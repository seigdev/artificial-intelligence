{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The afternoon sun cast long shadows across the quiet street as a gentle breeze rustled the golden leaves clinging stubbornly to the trees.',\n",
       " 'A faint scent of freshly brewed coffee drifted from a nearby café, mingling with the distant hum of traffic.',\n",
       " 'A cyclist whizzed past, their scarf fluttering behind them like a banner in the wind.',\n",
       " 'Across the road, an elderly man sat on a bench, flipping through a well-worn book, occasionally glancing up as if expecting someone.',\n",
       " 'The world moved at its usual pace, yet there was an air of quiet anticipation, as though something just beyond the horizon was about to unfold.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = \"The afternoon sun cast long shadows across the quiet street as a gentle breeze rustled the golden leaves clinging stubbornly to the trees. A faint scent of freshly brewed coffee drifted from a nearby café, mingling with the distant hum of traffic. A cyclist whizzed past, their scarf fluttering behind them like a banner in the wind. Across the road, an elderly man sat on a bench, flipping through a well-worn book, occasionally glancing up as if expecting someone. The world moved at its usual pace, yet there was an air of quiet anticipation, as though something just beyond the horizon was about to unfold.\"\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afternoon', 'sun', 'cast', 'long', 'shadows', 'across', 'quiet', 'street', 'gentle', 'breeze', 'rustled', 'golden', 'leaves', 'clinging', 'stubbornly', 'trees', '.']\n",
      "['faint', 'scent', 'freshly', 'brewed', 'coffee', 'drifted', 'nearby', 'café', ',', 'mingling', 'distant', 'hum', 'traffic', '.']\n",
      "['cyclist', 'whizzed', 'past', ',', 'scarf', 'fluttering', 'behind', 'like', 'banner', 'wind', '.']\n",
      "['across', 'road', ',', 'elderly', 'man', 'sat', 'bench', ',', 'flipping', 'well-worn', 'book', ',', 'occasionally', 'glancing', 'expecting', 'someone', '.']\n",
      "['world', 'moved', 'usual', 'pace', ',', 'yet', 'air', 'quiet', 'anticipation', ',', 'though', 'something', 'beyond', 'horizon', 'unfold', '.']\n"
     ]
    }
   ],
   "source": [
    "# apply stop words\n",
    "for i in range(len(sentences)):\n",
    "    # change sentence to lowercase.\n",
    "    sentences[i] = sentences[i].lower()\n",
    "    # perform word tokenization first.\n",
    "    words = nltk.word_tokenize(sentences[i]) \n",
    "    # return word in the list of words not present in stopwords using list comprehension\n",
    "    new_words = [word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    # sentences[i] = \" \".join(new_words) # converting all the new words into sentences\n",
    "    print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
